\documentclass[12pt]{report}
\usepackage{fancyvrb,graphicx,natbib,url,comment,import,bm}
\usepackage{tikz}

% Margins
\topmargin -0.1in
\headheight 0in
\headsep 0in
\oddsidemargin -0.1in
\evensidemargin -0.1in
\textwidth 6.5in
\textheight 8.3in

% Sweave options
\usepackage{Sweave}
\SweaveOpts{keep.source=TRUE,prefix.string=plots-ug/ug,png=TRUE,pdf=FALSE}

\DefineVerbatimEnvironment{Sinput}{Verbatim}{fontshape=sl,fontsize=\footnotesize}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{fontsize=\footnotesize}
\DefineVerbatimEnvironment{Scode}{Verbatim}{fontsize=\footnotesize}
%\fvset{listparameters={\setlength{\topsep}{0pt}}}
\renewenvironment{Schunk}{\vspace{0pt}}{\vspace{0pt}}

\DefineVerbatimEnvironment{Rcode}{Verbatim}{fontsize=\footnotesize}
\newcommand{\edgeR}{edgeR}
\newcommand{\pkgname}{dacpet}
\newcommand{\code}[1]{{\small\texttt{#1}}}
\newcommand{\R}{\textsf{R}}

% Defining a comment box.
\usepackage{framed,color}
\definecolor{shadecolor}{rgb}{0.9, 0.9, 0.9}
\newenvironment{combox}
{ \begin{shaded}\begin{center}\begin{minipage}[t]{0.95\textwidth} }
{ \end{minipage}\end{center}\end{shaded} }


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{\pkgname{}: \textit{De novo} analysis of ChIA-PET data \\ \vspace{0.2in} User's Guide}
\author{Aaron Lun}

% Set to change date for document, not compile date.
\date{First edition 10 July 2014\\
\vspace{6pt}
Last revised 17 November 2014}

% Removing the bibliography title so it shows up in the contents.
\makeatletter
\renewenvironment{thebibliography}[1]{%
%     \section*{\refname}%
%      \@mkboth{\MakeUppercase\refname}{\MakeUppercase\refname}%
      \list{\@biblabel{\@arabic\c@enumiv}}%
           {\settowidth\labelwidth{\@biblabel{#1}}%
            \leftmargin\labelwidth
            \advance\leftmargin\labelsep
            \@openbib@code
            \usecounter{enumiv}%
            \let\p@enumiv\@empty
            \renewcommand\theenumiv{\@arabic\c@enumiv}}%
      \sloppy
      \clubpenalty4000
      \@clubpenalty \clubpenalty
      \widowpenalty4000%
      \sfcode`\.\@m}
     {\def\@noitemerr
       {\@latex@warning{Empty `thebibliography' environment}}%
      \endlist}
\makeatother

\begin{document}
\maketitle
\tableofcontents

<<results=hide,echo=FALSE>>=
dir.create("plots-ug")
@

\newpage

\chapter{Introduction}
\section{Scope}
This document describes the use of the \pkgname{} package for \textit{de novo} identification of protein-mediated interactions from CHIA-PET data.
In particular, specific interactions are distinguished from non-specific ligation events by comparing the homo-linker and hetero-linker counts.
Analyses can also be performed to identify differential interactions between biological conditions.
This is done in a statistically rigorous manner using the methods in the \edgeR{} package \citep{edgeR}. 
Knowledge of \edgeR{} is useful, but not necessary.

\section{How to get help}
Most questions about individual functions should be answered by the documentation.  
For example, if you want to know more about \code{preparePET}, you can bring up the documentation by typing \code{?preparePET} or \code{help(preparePET)} at the \R{} prompt. 
If that doesn't help, reading this guide or contacting one of the authors is probably the best approach.
Bug reports and thoughtful suggestions for improvements are occasionally appreciated.

\section{Quick start}
<<echo=FALSE,results=hide>>=
curfiles <- c("SRR372741_AA.h5", "SRR372741_AB.h5", "SRR372741_BB.h5",
            "SRR372742_AA.h5", "SRR372742_AB.h5", "SRR372742_BB.h5")
@

The analysis of ChIA-PET data with \pkgname{} involves a number of steps.
For simplicity, assume that the BAM files have already been processed to tag files in \code{curfiles}.
Also assume that self-ligation events have been removed.
The code itself can then be written as:
\begin{enumerate}
\item converting BAM files to tag files
\item removing self-ligation events
\item counting tag pairs for each interaction
<<>>=
require(dacpet)
countwidth <- 5000
data <-countPET(curfiles, width=countwidth, filter=10)
freqs <- compressMatrix(data)
@
\item filtering out low-abundance interactions
<<>>=
require(edgeR)
ab <- aveLogCPM(asDGEList(freqs))
freqs <- freqs[ab > -1,]
@
\item normalizing the linker combinations
<<>>=
binned <-countPET(curfiles, width=1e7, filter=1)
rebin <- compressMatrix(binned)
inters <- rebin[is.na(getDistance(rebin)),]
normfacs <- normalize(inters)
@
\item modelling biological variability
<<>>=
y <- asDGEList(freqs, norm.factors=normfacs)
design <- model.matrix(~factor(info(freqs)$hetero))
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)
@
\item testing for significant differences between homo-/hetero-linker counts
<<>>=
result <- glmQLFTest(fit)
@
\end{enumerate}
In the various examples for this guide, data will be used from a ChIA-PET experiment targeting RNA polymerase II in MCF7 cells \citep{li2012extensive}. 
Obviously, readers will have to modify the code according to their own circumstances.

\chapter{Preparing tag files}

\section{Splitting tags and aligning reads}
As its name suggests, the ChIA-PET procedure generates paired-end sequencing data.
Each read in a pair has a tag and linker component as the $5'$ and $3'$ segment, respectively.
The linker component for each read must be identified as either A or B, based on the known linker sequence.
Then, it must be removed so that the tag can be aligned to the reference genome.
Removal is achieved with the \code{splitLinkers} function, which takes two FastQ files of tag-linker pairs and generates several paired FastQ files.
Each pair of files contains the tag pairs corresponding to each linker combination, i.e., AA, BB, AB or other/unknown.

<<eval=FALSE>>=
require(dacpet)
splitLinkers(fastq1="SRR372741_1.fastq", fastq2="SRR372741_2.fastq", 
    linkerA="GTTGGATAAGATATCG", linkerB="GTTGGAATGTATATCG")
@

<<echo=FALSE>>=
require(dacpet)
@

In older ChIA-PET datasets, reads were 36 bp long to accommodate a 20 bp tag and a 16 bp linker.
The \code{splitLinkers} function will automatically assume that the last 16 bp of the read represents the linker.
In newer experiments, longer read lengths are typically used.
The read position at which the linker starts must then be specified manually with the \code{start} parameter. 
This should be set to 20 - 21 bp if the restriction enzyme used is \textit{Mme}I.

The alignment itself can be performed with an appropriate aligner like \textsf{Bowtie2} \citep{langmead2012bowtie}.
Users should choose a mapping program that can handle 20 bp tags.
This should also be done in a manner that does not enforce similar mapping locations for paired tags, as each pair represents an interaction between distinct loci.
Duplicate marking with the \textsf{MarkDuplicates} tool from the Picard suite (\url{http://broadinstitute.github.io/picard}) is recommended.
The ultimate aim is to produce a name-sorted BAM file for each linker combination in each library, i.e., 3 BAM files.
For the MCF7 dataset, this results in 6 files in total after processing and mapping (ignoring those with unknown linkers):

<<>>=
bamfiles <- c("SRR372741_AA.bam", "SRR372741_AB.bam", "SRR372741_BB.bam", 
        "SRR372742_AA.bam", "SRR372742_AB.bam", "SRR372742_BB.bam")
@

Note that the three BAM files named \code{SRR372741\_*} correspond to a single ChIA-PET library, as do those named \code{SRR372742\_*}. 
These two libraries represent biological replicates, according to the entry in the NCBI Gene Expression Omnibus (accession number GSE33664).
They will be used later to assess the reproducibility of the identified interactions.

\section{Converting BAM files to tag files}
Repeated parsing of the BAM file is quite laborious for routine analyses.
Instead, the BAM file is parsed once to generate a processed tag file in HDF5 format.
Each tag file contains a number of \code{data.frame} objects, each of which contains all tag pairs mapped between a particular pair of chromosomes. 
Information can then be extracted efficiently from the tag file for downstream processing. 
This parsing is performed using the \code{preparePET} function to generate a tag file for each BAM file in the dataset. 

<<eval=FALSE>>=
incoming <- bamfiles[1]
outcoming <- sub("\\.bam", ".h5", incoming)
out <- preparePET(incoming, outcoming, minq=20, dedup=TRUE)
@

<<echo=FALSE>>=
incoming <- bamfiles[1]
outcoming <- "SRR372741_AA_new.h5"
out <- preparePET(incoming, outcoming, minq=20, dedup=TRUE)
@

The value of \code{minq} describes the minimum mapping quality score (MAPQ) for aligned tags. 
Both tags in each pair must have a MAPQ above \code{minq} for that pair to be retained in the tag file.
A reasonably stringent value is recommended given that alignment of short tags is likely to be error-prone.
Similarly, the \code{dedup} value specifies whether or not marked duplicates should be removed. 
This is recommended as the chance of randomly obtaining pairs with the same positions in the genome-by-genome space is low. 
Any overlaps are likely to be technical artifacts from PCR duplication during library preparation.
The numbers of pairs with at least one poorly mapped or duplicate tag can be examined in the output:

<<>>=
out$pairs
@

In most cases, the duplicate tags are also those with low mapping qualities as the aligner tends to place unknown sequences within alignable regions. 
The total number of tag pairs is also shown, along with the number of pairs that are retained in the final tag file.
You can also have a look at the number of single tags or those with more than two aligned segments. 
These should be non-existent, otherwise it suggests that the BAM file is malformed.

<<>>=
out$other
@

For brevity, this processing step is only performed here for one BAM file. 
Real analyses should run this function over a loop for all files (and store diagnostics) as required.

\section{Diagnosing ligation quality}

\subsection{Making strand orientation plots}
\label{ssec:strorient}
Some diagnostics can be pulled out of each processed tag file using the \code{diagnosePET} function. 
This extracts the strand information for inter-chromosomal tag pairs, i.e., those with tags mapped to different chromosomes.  
Each code refers to the combination of strands to which the tags in each pair are mapped, i.e., both forward (\code{0}), forward-reverse (\code{1}), reverse-forward (\code{2}) and both reverse (\code{3}). 
As you can see, these numbers are fairly balanced as ligation between different pieces of DNA can generate any combination of strands.

<<>>=
diag <- diagnosePET(outcoming)
diag$inter
@

The function will also collect strand and gap information for intra-chromosomal tag pairs. 
In this case, the ``first'' tag in a pair is the one that maps at a lower genomic position on that chromosome.
This means that a code of \code{1} marks an inward-facing tag pair (forward-reverse) whereas a code of \code{2} marks an outward-facing tag pair (reverse-forward). 
The gap distance refers to the distance between tag positions on the same chromosome. 
The distribution of gaps can then be examined for each strand orientation \citep{jin2013highres}. 
The average distribution of codes \code{0} and \code{3} is shown as both involve alignment to the same strand.

<<eval=FALSE,label=strorient>>=
lgap <- log2(diag$gap+1)
breaks <- seq(min(lgap), max(lgap), length.out=30)
iwin <- hist(lgap[diag$flag==1L], plot=FALSE, breaks=breaks)
owin <- hist(lgap[diag$flag==2L], plot=FALSE, breaks=breaks)
ssin <- hist(lgap[diag$flag==0L | diag$flag==3L], plot=FALSE, breaks=breaks)
   
plot(owin$mids, owin$counts/1e6, type="l", xlab=expression(log[2]~"[Gap (bp)]"), 
    ylab="Frequency (millions)", col="red", lwd=2, cex.lab=1.4, cex.axis=1.2)
lines(iwin$mids, iwin$counts/1e6, col="darkgreen", lwd=2)
lines(ssin$mids, ssin$counts/2e6, col="blue", lwd=2)
legend("topright", c("inward", "outward", "same"), col=c("darkgreen", "red", "blue"), 
    cex=1.3, lwd=2)
@

\begin{center}
<<fig=TRUE,echo=FALSE>>=
<<strorient>>
@
\end{center}

The spike in outward-facing tag pairs is consistent with self-ligation events.
This occurs when a DNA fragment ligates to itself to form a circle. 
Subsequent cleavage and sequencing over the ligation junction can only generate outward-facing pairs upon alignment. 
In contrast, inter-ligation events between DNA fragments can generate any of the strand orientation. 
This results in the equality that is observed between the distributions at higher gap sizes.

In theory, no skews in strand orientation should exist for the AB library. 
This is because all AB pairs should be formed by inter-ligation events. 
Nonetheless, self-ligation spikes will still be observed for the AB library.
This is probably due to spillover from linker assignment errors. 
The majority of AB tag pairs are inter-chromosomal so the absolute number of spillover pairs is usually negligble, regardless of the size of the peak in those plots.

\subsection{Mopping up outward-facing tag pairs}
Self-ligation events provide no information with respect to interactions between DNA fragments. 
Moreover, they can confound the analysis by masking genuine interactions during counting. 
Any tag pairs corresponding to self-ligation events should be removed with the \code{stripOutwardPET} function. 
This is done by removing all pairs contributing to the spike in the plot above, i.e., all outward-facing pairs at gap distances below 25 kbp.
 
<<>>=
stripfile <- sub("\\.h5", "_strip.tsv", outcoming)
stripped <- stripOutwardPET(outcoming, min.gap=25000, discard.to=stripfile)
stripped
@

This will overwrite the old tag file with the stripped results. 
The stripped results can be diverted to a new tag file by setting the \code{file.out} parameter, if further work on the original results is required.
The return value of the function represents the number of tag pairs discarded in this manner. 
This is usually a substantial proportion of all pairs in the original tag file. 
Here, the discarded pairs are also routed into \code{stripfile} for later use.

\chapter{Counting tag pairs into interactions}
\label{chap:counting}

\section{Motivation}
The aim of the ChIA-PET data analysis is to identify specific interactions between pairs of genomic binding sites. 
The evidence for an interaction can be summarized in terms of the number of tag pairs connecting the corresponding binding sites.
Recall that each tag pair is associated with a linker combination.
Specific interactions are those where the homo-linker count (i.e., AA or BB) is significantly greater than the hetero-linker count (i.e., AB).
This is because the latter can only be formed from non-specific ligation between complexes. 

The analysis will be demonstrated using the full MCF7 dataset. 
Some work is necessary to determine which files contain the hetero-linker counts, and which files correspond to a single library.
These identifiers will be used later to collapse counts for each linker combination into homo- or hetero-linker counts for each library.

<<>>=
curfiles <- c("SRR372741_AA.h5", "SRR372741_AB.h5", "SRR372741_BB.h5",
             "SRR372742_AA.h5", "SRR372742_AB.h5", "SRR372742_BB.h5")
is.het <- grepl("AB", curfiles)
libname <- sub("_[AB][AB].h5", "", basename(curfiles))
data.frame(curfiles, is.het, libname)
@

\section{Using windows or bins}
\label{sec:bincount}
\subsection{Overview}
Tag pairs must be summarized into counts for interactions prior to statistical analysis. 
The simplest strategy for doing so is to count tag pairs into pairs of bins. 
Partition the genome into contiguous and non-overlapping bins of equal size. 
For each pair of bins, the number of tag pairs with one tag mapped to each bin can be counted.  
This is performed for each linker combination in each library such that a set of counts is obtained for each bin pair.

<<>>=
countwidth <- 5000
actual <- countPET(curfiles, width=countwidth, filter=10)
actual
@

The returned \code{IList} object contains the counts for each bin pair in each tag file.
Each row of the count matrix represents one bin pair, and each column represents a corresponding entry in the input \code{curfiles}.
Each bin pair consists of one anchor and one target bin, both of which can be obtained with the \code{anchors} and \code{targets} methods. 
To avoid redundant permutations, the anchor bin is defined as that with the higher genomic coordinate.
Information about each tag file, such as the total number of PETs, is contained in the \code{info} slot.

The function can also be used to count tag pairs across pairs of sliding windows across the genome. 
This provides greater spatial resolution than bins as optimal counting can be achieved for features that cross bin boundaries.
However, it is more laborious and generates overlapping window pairs that are difficult to interpret. 
The gains in resolution are minor given the sparsity of tag pairs throughout the genome-by-genome interaction space.

\subsection{Consequences of reverse read extension}
The strategy described above considers a tag as ``within'' a bin if the $3'$ end of the tag is contained within the bin. 
The $3'$ end is more important than the $5'$ end as the former marks the end of the sonicated DNA fragment whereas the latter just marks the \textit{Mme}I cut site \citep{fullwood2010chiapet}.
If a bin overlaps a $3'$ end, it means that the bin spans part of the immunoprecipitated fragment. 
In contrast, overlaps to the $5'$ end do not have any obvious interpretation. 
Of course, this makes little practical difference for short 20 bp tags.

The gap between two $3'$ ends in an outward-facing read pairs represents the interval spanned by the DNA in the immunoprecipitated chromatin fragment. 
This suggests that the location of the peak in the strand orientation plot of Section~\ref{ssec:strorient} represents the average fragment length in the chromatin complexes after sonication and immunoprecipitation. 
In this case, the average fragment length is around 1 kbp.
Each tag can then be extended from its $3'$ end \textit{in the reverse direction of the strand} to this average length. 
The reverse-extended tag then represents the putative interval spanned by the original fragment. 

This reverse extension can be performed by setting the \code{ext} parameter to the average fragment length in \code{countPET}. 
Counts are then defined for each bin pair as the number of tag pairs where one extended tag overlaps each bin. 
In practice, simply increasing the width of each bin by twice the average fragment length will have the same effect (see below).

\subsection{Choosing an appropriate width}
The width of each bin in \code{countPET}  must be specified by the user during counting. 
A large \code{width} will count more tag pairs and increase detection power in downstream testing. 
This comes at the expense of spatial resolution whereby adjacent events can no longer be distinguished. 
In general, loss of resolution can be damaging as the count for the feature of interest becomes contaminated with irrelevant counts from adjacent features. 
This can dilute or mask significant differences between the homo- and hetero-linker counts. 

For most ChIA-PET datasets, modest overestimation of the width will have little effect as the degree of contamination is limited by the sparsity of tags in the surrounding interaction space. 
This argument also justifies the use of a larger \code{width} rather than \code{ext}. 
The only difference between the two parameters is that reverse extension is strand-specific whereas the width is not.
This will not have a major effect on the results due to the aforementioned sparsity.  
Given that the average fragment length is around 1 kbp, a width of 5 kbp is used here so that all tags associated with a binding site are likely to be counted in a bin.

\subsection{Filtering for computational efficiency} 
Only bin pairs with a sum of counts across all libraries above \code{filter} will be retained. 
A reasonably large filter is necessary to avoid reporting an excessive number of uninteresting bin pairs that contain very few (e.g., single-digit) tag pairs. 
Otherwise, the downstream analyses will be very computationally intensive for little practical gain.  
Conversely, the filter value should not be too high, otherwise genuine interactions will be discarded. 
The appropriate choice of filter statistic and value is discussed in more depth in Section~\ref{sec:filtering}.

\section{Using peaks}

\subsection{Peak calling from outward-facing pairs}
An alternative approach is to identify binding sites using peak calling programs like MACS \citep{zhang2008macs}. 
These can be run on the outward-facing tag pairs that were previously pruned out of the tag file.
This is equivalent to the cluster identification step in the ChIA-PET software tool \citep{li2010tool}. 
Outward-facing pairs are more reliable as the presence of both tags at a site indicates that they are more likely to be properly mapped.

\subsection{Pooling to a BED file}
Here, the outward-facing pairs from all tag files are pooled together and stored in a BED file. 
Pooling is recommended as it ensures that a single set of peaks can be obtained from the entire dataset. 
This means that consolidation of multiple peak sets is not required. 
It also increases the number of tags involved for sensitive peak calling.
 
<<eval=FALSE>>=
require(rtracklayer)
discard.files <- list.files(".", pattern="_strip.tsv$")
output.file <- "pooled.bed"
start <- TRUE
for (x in discardfiles) {
    current <- read.table(x, stringsAsFactors=FALSE)
    chosen.strand <- rbinom(nrow(current), 1, 0.5)==1L
    chosen.pt <- ifelse(chosen.strand, current[,3], current[,2])
    export(GRanges(current[,1], IRanges(chosen.pt, chosen.pt), strand=chosen.strand),
        con=output.file, format="bed", append=!start)
    start <- FALSE
}
@

Technically, all libraries should be pooled to maintain statistical validity during peak calling.
This ensures that the called peaks are independent of the downstream hypothesis tests for specificity.
In practice, self-ligation events should dominate the outward-facing tag pairs. 
This means that only homo-linker tag pairs need to be used for peak calling.
Indeed, very few hetero-linker tag pairs should be present in the discarded set.

% Assume there are no self-ligation events. 
% Any outward-facing tag pairs are generated from inter-ligation events and will be correlated with the other strand orientations. 
% Peak calling on outward-facing homo-linker tag pairs will select for interactions with large homo-linker counts (based on the other orientations). 
% This compromises the independence between peak definition and % statistical testing.  
% In particular, interactions are likely to be selected that have spurious differences between homo- and hetero-linker counts.

The tags themselves are stored as if they were generated from a ChIP-seq experiment. 
For each outward pair, the left tag is mapped to the reverse strand for a ChIA-PET experiment, but must be switched to the forward strand to mimic a ChIP-seq experiment. 
The same logic applies for the right tag. 
Only one tag is randomly taken from each fragment to mimic single-end data, given that many peak-callers cannot directly handle paired-end data.

\subsection{Reading peaks and checking widths}
So, assume that you got your peak-caller to save the results in \code{peak.file}. 
In this case, MACS \citep{zhang2008macs} was called with the options \code{-t pooled.bed -f BED -n here -{}-nomodel}. 
The peaks can then be loaded into a \code{GRanges} object after peak calling, as shown below:

<<>>=
peak.file <- "here_peaks.bed"
peak.tab <- read.table(peak.file, stringsAsFactors=FALSE)
peaks <- GRanges(peak.tab[,1], IRanges(peak.tab[,2], peak.tab[,3]))
peaks
@

It is a good idea to check the widths of the identified peaks. 
For some peak callers, very small intervals will be identified so it may be necessary to expand the width of each peak. 
In this case, all peaks are expanded to 2 kbp in width and any overlapping peaks are merged. 
This minimum width is justified as being twice the (estimated) average fragment length for this dataset, such that all tags associated with a binding site will be counted.

<<>>=
summary(width(peaks))
peaks <- resize(peaks, fix="center", width=pmax(2000, width(peaks)))
peaks <- reduce(peaks)
summary(width(peaks))
@

For each pair of peaks, the number of tag pairs is counted based on the presence of the $3'$ end of one tag within each peak interval. 
This represents the number of connections between two putative binding sites. 
Counting can be performed using the \code{recountPET} function, along with some filtering on the count sum with \code{filter} as previously described. 
Reverse read extension can also be performed with \code{ext} but, again, this is probably unnecessary. 

<<>>=
peaked <- recountPET(curfiles, peaks, filter=10)
peaked
@

\section{Aggregating homo- and hetero-linker counts}
As previously mentioned, the aim of the analysis is to compare homo- and hetero-linker counts. 
The presence of separate AA and BB counts is redundant for this purpose. 
To simplify the count matrix, the homo-linker counts for each library can be added together. 
This is done with the \code{compressMatrix} function for either the binned or peak-based counts. 

<<>>=
freqs <- compressMatrix(actual, is.het, libname)
freqs
@

The total number of tag pairs in each \textit{library} (not tag file) is also computed. 
Each total includes tag pairs from all linker combinations, and both homo-/hetero-linker columns from the same library are assigned the same total. 
This is appropriate as the total reflects the sequencing depth, which is constant for all counts derived from the same library.

% More concretely, one can imagine a situation where there are many genuine
% interactions.  This means that there will be widespread increases in the
% homo-linker counts relative to the hetero-linker counts. If the total was
% defined the number of tag pairs for each linker type, the hetero-linker total
% would be much smaller than the homo-linker total. Normalization would then
% scale up counts for the former, reducing detection of differences.

\section{Filtering to remove uninteresting features}

\subsection{By distance}
Local interactions are frequently observed as pairs of the same or adjacent regions. 
These are usually uninteresting as they are inevitable consequences of chromatin compaction. 
The gap distance between the interacting regions can be computed with the \code{getDistance} function. 
This refers to the distance between the interacting regions on the same chromosome. 

<<>>=
gapped <- getDistance(freqs)
summary(gapped)
@

Local interactions can then be discarded by putting a minimum threshold on the gap. 
This avoids confounding the results with many genuine yet uninteresting local interactions. 
For the binning strategy, setting a minimum gap of 1 or more will select for pairs of bins that are non-adjacent. 
Any inter-chromosomal pairs are marked as \code{NA} and must also be included.

<<>>=
keep <- gapped > 1 | is.na(gapped)
freqs <- freqs[keep,]
sum(keep)
@

% Specifically, you want to avoid kicking out the FDR for the interesting
% long-range interactions.

\subsection{By abundance}
\label{sec:filtering}
Low-abundance interactions are those with low tag pair counts. 
These do not provide enough evidence for rejection of the null hypothesis during later testing. 
They are also more likely to represent weak and uninteresting non-specific ligation events.
Removal of these interactions can improve the sensitivity of the analysis by reducing the total number of tests and mitigating the severity of the multiple testing correction. 
Filtering on the average count (as computed by the aveLogCPM function in the \edgeR{} package \citep{mccarthy2012glm}) is recommended for statistical analyses using a negative binomial (NB) model.

<<>>=
require(edgeR)
ab <- aveLogCPM(asDGEList(freqs))
summary(ab)
@

The average count is useful as it is approximately independent of the $p$-value in \edgeR{} \citep{lun2014denovo}.
This ensures that the filtering procedure will not affect the validity of the ensuing statistical analysis. 
Of course, some caution is required lest all the interesting interactions be removed.  
In this case, a relatively mild threshold is used given that the bulk of filtering has already been performed with \code{filter} during count loading.

<<>>=
keep <- ab > -1
freqs <- freqs[keep,]
summary(keep)
@

A more educated choice of filter threshold can be obtained by identifying genuine interactions as those that have higher average abundances than a non-specific interaction. 
If one assumes that most of the interaction space is filled with non-specific contacts, it is simple to calculate the threshold based on the abundance of those contacts. 
Note that larger bins are required to count non-specific contacts due to the sparsity of the interaction space. 

<<>>=
binsize <- 1e6
binned <-countPET(curfiles, width=binsize, filter=1)
rebin <- compressMatrix(binned, hetero=is.het, libname=libname)
@

The abundance of larger bin pairs can be calculated and compared to the values in \code{ab}.
Some adjustments are necessary to account for the differences in the areas of the interaction space that are used for tag pair collection with each bin size.
The median of the adjusted values is used as the estimate for the rate of non-specific ligation.
Here, each smaller bin pair is only retained if its abundance is 5 times higher than the non-specific estimate.

<<>>=
require(csaw)
threshold <- median(scaledAverage(asDGEList(rebin), scale=(binsize/countwidth)^2))
keep <- ab >= threshold + log2(5) 
summary(keep)
@

% You might well ask, why bother doing the testing if you're just going to
% select for it here? The answer is that this selection doesn't compute
% p-values. To do so requires some assumptions about the distribution of tags
% across the interaction space, which may be stronger than desirable (especially
% when ligation is non-random, so a random distribution isn't appropriate).
% Also, even though the enrichment looks really strong, you have to consider
% the effects of multiplicity correction across the entire interaction space.
% I'm not sure that just saying 'two connecting PETs = interaction" is
% really good enough, especially given that it could occur for the heteros.

\chapter{Normalizing linker combinations}

\section{Motivation}
Some normalization is necessary prior to making comparisons between homo- and hetero-linker counts. 
This accounts for biases introduced by non-equal proportions of the two linkers, as well as any effects of non-random ligation. 
Failure to normalize will lead to incorrect conclusions. 
In particular, the nominal expected ratio of homo- to hetero-linker counts is 1:1 in a na\"ive comparison. 
The true expected ratio is often higher for a number of reasons (see below), so testing against the nominal ratio will result in many false positives.

\section{Diagnosing random ligation}

\subsection{Using the Hardy-Weinberg law for normalization}
Each DNA fragment can be treated as a ``diploid individual'', such that each end represents an ``allele''. 
Random ligation between ends of DNA fragments is equivalent to random mating between individuals. 
Now, assume that the proportions of DNA fragments attached to linker A and B are $a$ and $b=1-a$, respectively. 
Under the Hardy-Weinberg law, this means that the the proportion of AA, AB and BB would be $a^2$, $2ab$ and $b^2$, respectively.

This result is useful as it allows normalization to remove the effects of non-equal A and B proportions, i.e., $a\ne b$. 
Consider a case when $a=0.5b$. 
The expected homo- to hetero-linker ratio would then be 5:4. 
If you failed to consider this effect, you would (incorrectly) expect a ratio of 1:1 for a na\"ive comparison.  
Any interactions with the true expected ratio would deviate from the incorrect expected ratio, increasing the proportion of false positives. 

This problem can be avoided with normalization. 
The value of $a$ can be empirically determined from the proportion of tags that were attached to linker A. 
The expected proportions for each linker can then be calculated based on the Hardy-Weinberg law. 
These proportions are easily transformed into an expected ratio for the homo- and hetero-linker counts. 
Alternatively, normalization can be performed to coerce the expected ratio to a standard 1:1 setup.
In the example above, the expected ratio is 5:4. 
One could then normalize the data by dividing the homo-linker counts by 1.25 prior to any hypothesis testing.

\subsection{Checking mitochondrial counts}
The accuracy of the random ligation model can be assessed with \code{extractMito}.
This counts the tag pairs mapped between the nuclear and mitochondrial chromosomes for each tag file.
The assumption here is that the mitochondrial genome does not interact with nuclear chromosomes. 
This is fairly reasonable given that they belong to separate organelles. 
Thus, any counts observed here are attributable to non-specific (and presumably random) ligation.

<<>>=
mitocounts <- sapply(curfiles, FUN=function(x) { sum(extractMito(x)) })
mitocounts
@

It is fairly obvious that these counts do not follow the predicted Hardy-Weinberg proportions. 
This can be confirmed by using Pearson's chi-squared test.
So, does this correspond to some fascinating new biology involving inter-organelle interactions? 
Well, probably not. 
It just means that non-specific ligation is not necessarily random.

<<>>=
lib.1 <- mitocounts[1:3]
prop.a <- (lib.1[1]*2 + lib.1[2])/sum(lib.1)/2
expected <- c(prop.a^2, prop.a*(1-prop.a)*2, (1-prop.a)^2)
expected
chisq.test(lib.1, p=expected)
@

\subsection{Checking counts across the interaction space}
The mitochondrial results can be confirmed with counts from the rest of the dataset. 
Tag pairs are counted into pairs of 10 Mbp bins as described before. 
The assumption here is that most inter-chromosomal bin pairs only contain non-specific ligation events.
This is generally reasonable as chromosomes are organized into self-contained territories within the nucleus \citep{bickmore2013spatial}.
This sterically limits the potential contacts between loci on different chromosomes.
Again, large bins are necessary to count these rare non-specific events.

<<>>=
binned <-countPET(curfiles, width=1e7, filter=1)
rebin <- compressMatrix(binned, hetero=is.het, libname=libname)
head(counts(rebin))
@

The M-value for each interaction is defined as the log-ratio of homo- to hetero-linker counts. 
This is used to construct a MA plot as shown below.  
If non-specific ligation is random, the expected M-value under the random ligation model should be observed (red line). 
However, the bulk of interactions have substantially higher M-values. 
This is consistent with the above-expected homo-linker counts for the nuclear-mitochondrial ``interactions''.
That the inter-chromosomal M-values are generally equal to or less than the nuclear-mitochondrial M-values (crosses) also suggests that most inter-chromosomal contacts are non-specific.

<<eval=FALSE,label=plotma>>=
adj.counts <- cpm(asDGEList(rebin), log=TRUE)
m <- adj.counts[,1]-adj.counts[,2]
a <- adj.counts[,1]+adj.counts[,2]
smoothScatter(x=a, y=m, xlab="A", ylab="M", main=info(rebin)$libname[1], cex.lab=1.4, cex.axis=1.2)
abline(h=log2((expected[1]+expected[3])/expected[2]), col="red")
has.mito <- as.logical(seqnames(anchors(rebin)) == "chrM" | seqnames(targets(rebin)) == "chrM")
points(a[has.mito], m[has.mito], pch=4, cex=0.8)
@

\begin{center}
<<fig=TRUE,echo=FALSE>>=
<<plotma>>
@
\end{center}

This result supports the notion that non-specific ligation is not equivalent to random ligation. 
At the very least, non-randomness means that the random ligation model cannot be used for normalization. 
At worst, the ligation may be so non-random that there are no hetero-linker counts for any meaningful comparison. 
Note that different datasets may experience differing violations of the randomness assumption.
Making diagnostic plots like the one shown above is recommended for routine quality control.

\section{Normalizing for empirical effects}
\label{sec:norm}
Normalization must account for both non-equal linker proportions and non-random ligation. 
This can be done empirically by assuming, again, that most inter-chromosomal interactions are non-specific. 
This means that the average M-value for these interactions can be used to define the expected homo-/hetero-linker ratio under the null hypothesis of non-specificity.
In the MA plot above, most inter-chromosomal M-values are close to 2.
One would then expect a homo-/hetero-linker count ratio of around 4:1 for a non-specific interaction. 

Normalization can then be performed according to the expected ratio. 
Counts for inter-chromosomal bin pairs are passed to the trimmed mean of M-values (TMM) procedure \citep{oshlack2010tmm}. 
This returns a normalization factor for each homo-/hetero-linker column in each library. 
Counts are then (conceptually) divided by the normalization factor, and a comparison is directly performed between normalized counts. 
For example, an expected ratio of 4:1 would be normalized by dividing the homo-linker counts by 4.

<<>>=
inters <- rebin[is.na(getDistance(rebin)),]
normfacs <- normalize(inters)
normfacs
@

Note that only inter-chromosomal interactions are used in the TMM procedure. 
This weakens the assumption of a non-specific majority as genuine interactions between chromosomes are rarer than those within chromosomes. 
In the MA plot above, all inter-chromosomal interactions lie within the main bulk of M-values at $\sim$2 whereas only intra-chromosomal events are in the cloud at $\sim$7.
This is consistent with the greater specificity of the latter.

\chapter{Assessing biological variability}

\section{Motivation}
The availability of biological replicates means that the biological variability of the system can be modelled.
This reduces the significance of detected features when the data is highly variable. 
For count-based data, this can be achieved using the NB model in \edgeR{} \citep{edgeR}.  
Estimation of the NB dispersion parameter allows modelling of the variation between biological replicates. 
Similarly, estimation of the quasi-likelihood (QL) dispersion can be performed to account for heteroskedasticity \citep{lund2012ql}. 

Dispersion estimation requires fitting of a generalized linear model (GLM) to the counts for each interaction \citep{mccarthy2012glm}. 
To this end, the choice of a design matrix is critical. 
Multiple designs are available to parameterize the combination of homo-/hetero-linker and library. 
The effect of these choices will be discussed in the following section. 
Firstly, it is necessary to assemble a \code{DGEList} object for entry into \edgeR{}:

<<>>=
y <- asDGEList(freqs, norm.factors=normfacs)
@

\section{The paired-sample design}
\label{sec:paireddesign}
The most obvious choice is a paired-samples design, where the homo- and hetero-linker counts from a single library are paired together.
The aim is to identify differences between the homo- and hetero-linker counts within each pair. 
This design accommodates library-specific effects, i.e., differences in the absolute abundance between libraries will not affect the result as long as the homo-/hetero-linker count ratio is constant between libraries.
This avoids any inflation of the dispersions due to batch effects between libraries.

<<>>=
design.paired <- model.matrix(~factor(info(freqs)$libname) + factor(info(freqs)$hetero))
design.paired
@

Estimation of the dispersions can then be performed using methods in the \edgeR{} package. 
The \code{estimateDisp} function will estimate the NB dispersion whereas the \code{glmQLFit} function will estimate the QL dispersion. 
In both cases, the low number of replicates means that limited information is available to estimate the dispersion for each interaction. 
Thus, an empirical Bayes strategy is used to stabilise the estimates by sharing information between interactions. 
This is represented by the estimation of a mean-dispersion trend (for NB) and shrinkage of the per-interaction dispersion estimates towards a trend (for QL).

<<label=bcvpaired,eval=FALSE,echo=FALSE>>=
y.paired <- estimateDisp(y, design.paired)
plotBCV(y.paired)
@

<<label=qlpaired,eval=FALSE,echo=FALSE>>=
fit.paired <- glmQLFit(y.paired, design.paired, robust=TRUE)
plotQLDisp(fit.paired)
is.zero <- fit$df.residual.zeros==0L
points(fit.paired$AveLogCPM[is.zero], 0, pch=4)
@

<<eval=FALSE>>=
<<bcvpaired>>
<<qlpaired>>
@

Note that the biological coefficient of variation (BCV) is defined as the square root of the NB dispersion. 
This represents the proportion of the counts that is attributable to biological variability. 
The QL dispersion is estimated from the GLM deviance and is shown as such, with a quarter-root transformation applied for maximum visibility across the range of values.
Crosses indicate those bin pairs with no residual degrees of freedom in the fit.

\setkeys{Gin}{width=0.49\textwidth}
\begin{center}
<<fig=TRUE,echo=FALSE>>=
<<bcvpaired>>
@
<<fig=TRUE,echo=FALSE>>=
<<qlpaired>>
@
\end{center}
\setkeys{Gin}{width=0.8\textwidth}

For real datasets, the paired-sample design is not effective due to the frequency of zeros for the hetero-linker counts. 
This means that no residual degrees of freedom are available for dispersion estimation. 
Conceptually, you can imagine that the paired-sample design measures the variability of the homo-/hetero-linker fold change across libraries. 
Zeros for the hetero-linker counts means that the fold-change for each library will be undefined. 
This manifests as zero values for most of the QL dispersions in the plot above.

It may be possible to overcome this problem by adding a prior value onto the counts. 
This will avoid zeros and allow passage through the QL framework. 
However, this is a fairly arbitrary solution as the estimated dispersion will be sensitive to the choice of prior.
It will also lead to underestimation of the dispersion, as the hetero-linker count will become a non-zero constant that does not reflect the true variability of the counts.

\section{The one-way design}
Instead, routine ChIA-PET analyses should use a one-way layout for the design matrix. 
All hetero-linker counts are treated as a single group, and all homo-linker counts are treated as another group. 
This means that the NB and QL dispersions can be properly estimated from the non-zero homo-linker counts, even when the hetero-linker counts are all zero.

<<>>=
design.group <- model.matrix(~factor(info(freqs)$hetero))
design.group
@

Estimation can be performed as previously described. 
This approach avoids the zero-valued QL dispersions observed for the paired-sample design. 
Of course, it assumes that there are no library-specific effects. 
For example, if the abundance changed randomly between libraries but the homo-/hetero-linker fold change was constant, the dispersions would be inflated in the one-way design but not in the paired-sample design.
The homo-/hetero-linker group means would also be correlated, which could cause problems in downstream testing.

<<label=bcvgroup,eval=FALSE,echo=FALSE>>=
y.group <- estimateDisp(y, design.group)
plotBCV(y.group)
@

<<label=qlgroup,eval=FALSE,echo=FALSE>>=
fit.group <- glmQLFit(y.group, design.group, robust=TRUE)
plotQLDisp(fit.group)
@

<<eval=FALSE>>=
<<bcvgroup>>
<<qlgroup>>
@

\setkeys{Gin}{width=0.49\textwidth}
\begin{center}
<<fig=TRUE,echo=FALSE>>=
<<bcvgroup>>
@
<<fig=TRUE,echo=FALSE>>=
<<qlgroup>>
@
\end{center}
\setkeys{Gin}{width=0.8\textwidth}

Based on these results, inflation of the NB dispersion is not a problem here.
In fact, the NB dispersion is exceptionally low given that biological replicates are being compared. 
For other types of sequencing data like RNA-seq or ChIP-seq, dispersion estimates are usually around 0.01 to 0.1.
Much lower values are observed here, i.e., $<$ 0.01 after squaring the BCV.
This is a bit odd, as ChIA-PET should be at least as variable as ChIP-seq.
Oh well.

\chapter{Testing for significant interactions}

\section{Using the quasi-likelihood F-test}
The \code{glmQLFTest} function performs a QL F-test for each interaction, to identify those with significant differences between homo- and hetero-linker counts.
Users should make sure that they are specifying the contrast correctly (see the edgeR user's guide for more details).
For the one-way layout, the coefficient of interest is that corresponding to the homo-/hetero-linker fold change. 
This should be specified through the \code{coef} or \code{contrast} arguments.

<<>>=
result.group <- glmQLFTest(fit.group, coef=2)
topTags(result.group)
@

Recall that the null hypothesis is that the (normalized) hetero-linker counts are the same as the homo-linker counts. 
The computed $p$-value represents the evidence against this null for each interaction. 
The log-fold change represents that of the hetero-linker count over the homo-linker count.
In this case, they are negative for all interactions. 
This corresponds to more homo-linker counts and is consistent with the presence of specific interactions.

<<>>=
summary(result.group$table$logFC)
@

Discerning users may also be wondering why we are not using the likelihood ratio test (LRT).
Indeed, the LRT is the more obvious test for hypothesis testing in the GLM framework. 
However, the QL F-test is preferred here as it accounts for the variability and uncertainty of the QL dispersion estimates \citep{lund2012ql}. 
This means that it can maintain type I error control in the presence of heteroskedasticity whereas the LRT does not.

\section{Multiplicity correction and the FDR}
Correction for multiple tests is performed by controlling the false discovery rate (FDR), using the method described by \cite{benjamini1995fdr}. 
In this case, the FDR refers to the proportion of detected interactions that are false positives. 
Control of the FDR is often more appropriate than control of the family-wise error rate (i.e., probability of one or more false rejections across all interactions).
This is because the former provides a more appropriate compromise between specificity and power in genome-wide analyses.

<<>>=
adj.p <- p.adjust(result.group$table$PValue, method="BH")
sum(adj.p <= 0.05)
@

Significantly specific interactions are defined as those that are detected at an FDR of 5\%. 
These can be saved to file as necessary. 
In practice, all interactions should be sorted by the $p$-value and saved to file. 
This means that results can be queried in a flexible manner without needing to re-run the entire analysis, e.g., if the FDR threshold is changed.

<<>>=
ax <- anchors(freqs)
tx <- targets(freqs)
final <- data.frame(anchor.chr=seqnames(ax), anchor.start=start(ax), anchor.end=end(ax),
    target.chr=seqnames(tx), target.start=start(tx), target.end=end(tx), 
    result.group$table, FDR=adj.p)
o <- order(final$PValue)
write.table(final[o,], file="results.tsv", sep="\t", quote=FALSE, row.names=FALSE)
@

Note that the interactions of interest are those where the homo-linker count is greater than the hetero-linker count.
Power can be improved by filtering out all bin pairs with an inappropriate sign for the log-fold change, prior to applying the BH method.
This removes uninteresting tests and reduces the severity of the correction.
That said, filtering has no effect in this particular dataset as there are no bin pairs with a positive log-fold change. 

\section{Visualization with plaid plots}
There comes a time that some visualization of interesting results is desirable.
This can be performed using the \code{plotChIA} function, which constructs a plaid plot of the interaction space \citep{lieberman2009hic}. 
Briefly, each axis is a chromosome segment. 
The box represents an interaction between the corresponding points on each axis. 
The colour of the box is proportional to the number of tag pairs mapped between the interacting loci.

<<label=chia1aa,eval=FALSE,echo=FALSE>>=
expanded.a <- resize(ax[o[1]], fix="center", width=50000)
expanded.t <- resize(tx[o[1]], fix="center", width=50000)
plotChIA(curfiles[1], anchor=expanded.a, target=expanded.t, main="AA", cap=10)
rect(start(ax[o[1]]), start(tx[o[1]]), end(ax[o[1]]), end(tx[o[1]]))
abline(0, 1, lty=2)
@

<<label=chia1ab,eval=FALSE,echo=FALSE>>=
plotChIA(curfiles[2], anchor=expanded.a, target=expanded.t, main="AB", cap=5)
abline(0, 1, lty=2)
@

<<label=chia1bb,eval=FALSE,echo=FALSE>>=
plotChIA(curfiles[3], anchor=expanded.a, target=expanded.t, main="BB", cap=10)
abline(0, 1, lty=2)
@

<<eval=FALSE>>=
<<chia1aa>>
<<chia1ab>>
<<chia1bb>>
@

Expansion of the plot boundaries is recommended.
This shows the context of the interaction by examining the features in the surrounding interaction space. 
It is also possible to tune the width of the boxes through a parameter that is, rather unsurprisingly, named \code{width}.
The dotted line represents the diagonal around which the plot is symmetric. 
The actual interaction occurs at the center of the plot and is marked by a rectangle in the first plot.

\setkeys{Gin}{width=0.32\textwidth}
\begin{center}
<<fig=TRUE,echo=FALSE>>=
<<chia1aa>>
@
<<fig=TRUE,echo=FALSE>>=
<<chia1ab>>
@
<<fig=TRUE,echo=FALSE>>=
<<chia1bb>>
@
\end{center}

The \code{cap} value controls the relative scale of the colours. 
A smaller \code{cap} is necessary for the AB track to normalize the intensity, much like that discussed in Section~\ref{sec:norm}. 
In this case, a homo-/hetero-linker ratio of 4:1 is expected under the null, so the cap is (10+10):5. 
This means that the intensity of colours in the AB plot can be directly compared to those of AA and BB. 
Upon doing so, you'll find that the intensity of the homo-linkers is much greater than that of the hetero-linkers for this part of the interaction space. 
This suggests that the interaction is specific and genuine. 
Here's another example in a different colour:

<<label=chia2aa,eval=FALSE,echo=FALSE>>=
expanded.a <- resize(ax[o[3]], fix="center", width=50000)
expanded.t <- resize(tx[o[3]], fix="center", width=50000)
plotChIA(curfiles[1], anchor=expanded.a, target=expanded.t, main="AA", cap=10, col="blue")
@

<<label=chia2ab,eval=FALSE,echo=FALSE>>=
plotChIA(curfiles[2], anchor=expanded.a, target=expanded.t, main="AB", cap=5, col="darkgreen")
@

<<label=chia2bb,eval=FALSE,echo=FALSE>>=
plotChIA(curfiles[3], anchor=expanded.a, target=expanded.t, main="BB", cap=10, col="black")
@

<<eval=FALSE>>=
<<chia2aa>>
<<chia2ab>>
<<chia2bb>>
@

\setkeys{Gin}{width=0.32\textwidth}
\begin{center}
<<fig=TRUE,echo=FALSE>>=
<<chia2aa>>
@
<<fig=TRUE,echo=FALSE>>=
<<chia2ab>>
@
<<fig=TRUE,echo=FALSE>>=
<<chia2bb>>
@
\end{center}

Tying this in with gene annotation, ChIP-seq peaks and/or RNA-seq data can then suggest some functions for these interactions, e.g., enhancer loops, gene loops, gene-gene interactions. 
Of course, users should always keep the identify of the target protein in mind. 
This particular experiment targets RNA polymerase II so most activity will occur at genes and have a transcriptional focus. 
Other protein targets are likely to have different profiles.

\chapter{Repeating with differential analyses}

\section{Loading the homo-linker counts}
The previous analysis detects significantly specific interactions by comparing the homo-linker counts with the hetero-linker counts within a single condition.
True differential analyses involve comparison of counts between libraries for different conditions.
This can be more useful as differential interactions are more likely to be relevant to the biological difference of interest.
To demonstrate, data will be loadded from a ChIA-PET experiment targeting RNA polymerase II and generated from MCF7 and K562 cells \citep{li2012extensive}. 
A bin counting strategy is used here to extract the homo-linker counts in each library.

<<>>=
curfiles <- c("SRR372741_AA.h5", "SRR372741_BB.h5",
              "SRR372742_AA.h5", "SRR372742_BB.h5",
              "SRR372747_AA.h5", "SRR372747_BB.h5",
              "SRR372748_AA.h5", "SRR372748_BB.h5")
actual <-countPET(curfiles, width=countwidth, filter=10)
comp.freq <- compressMatrix(actual)
head(counts(comp.freq))
@

The aim is to identify interactions where the homo-linker counts for MCF7 and K562 cells are significantly different.
This is an effective strategy as homo-linker counts are large enough for stable inference in most ChIA-PET datasets.
In theory, hetero-linker counts could also be used to account for library-specific differences in ligation specificity.
However, these counts will not be included here as they are too small to be informative.
This is analogous to the discussion about paired-sample and one-way designs in Section~\ref{sec:paireddesign}.

\section{Filtering on abundance and distance}
Filtering is performed to remove low-abundance interactions for which detection power will always be low.
Local interactions are also removed as they provide no information with respect to chromatin organization.
This is equivalent to the strategies described in Section~\ref{sec:filtering}.

<<>>=
min.gap <- getDistance(comp.freq)
keep <- aveLogCPM(asDGEList(comp.freq)) > 0 &
	(min.gap > 1 | is.na(min.gap))
comp.freq <- comp.freq[keep,]
summary(keep)
@

\section{Normalizing differences between libraries}
Some normalization is required to correct for systematic biases prior to hypothesis testing.
One approach is to assume that most interactions are constant between MCF7 and K562 cells.
This means that the TMM method can be applied directly to the counts for the interactions.
Filtering beforehand is critical to ensure that the counts are large enough for sensible normalization on the M-values (i.e., transformed fold changes).
Of course, this is not applicable if one expects overall changes to the interaction structure between cell types.

<<>>=
y.diff <- asDGEList(comp.freq)
y.diff <- calcNormFactors(y.diff)
y.diff$samples
@

Alternatively, an approach analogous to homo-/hetero-linker normalization (see Section~\ref{sec:norm}) can be used.
Genuine biological differences are not expected between groups for non-specific interactions.
Any differences in the counts for these interactions are attributed to composition biases and other technical effects.
To remove such biases, the majority of inter-chromosomal contacts are assumed to be non-specific.
Reads are re-counted using large bins to provide sufficiently large counts for these weak contacts.
The TMM method can then be applied to compute appropriate normalization factors.

<<>>=
binned.diff <-countPET(curfiles, width=1e7, filter=1)
rebin.diff <- compressMatrix(binned.diff)
inter.counts <- asDGEList(rebin.diff[is.na(getDistance(rebin.diff)),])
inter.counts <- calcNormFactors(inter.counts)
normfacs <- inter.counts$samples$norm.factors
normfacs
@

The ideal approach depends on whether any consistent increases or decreases in interaction intensity are assumed to be genuine.
If so, the second approach should be used as it only removes differences for non-specific interactions.
This preserves any differences in the high-abundance specific interactions.
Otherwise, these differences are technical artifacts and should be removed with the first approach.

For this particular dataset, the second approach is chosen.
Large-scale changes are to be expected when comparing two different immortalized cell lines.
Note that the normalization factors computed with large bins can still be applied to the counts for the smaller bins.
This is because the same composition biases will be present throughout the dataset.

<<>>=
y.diff$samples$norm.factors <- normfacs
@

\section{Running through the statistical analysis}
As previously mentioned, users should perform the statistical analysis with a one-way layout.
Counts for each cell type are treated as replicates of a group.
The ensuing analysis will compare counts between the two cell types for each interaction.
The null hypothesis is that the second coefficient is zero, i.e., the normalized mean counts for each group are identical.

<<>>=
design.diff <- model.matrix(~factor(c("mcf7", "mcf7", "k562", "k562")))
design.diff
@

Dispersion estimation and hypothesis testing can be performed as previously described, using the QL framework from the \edgeR{} package.
For the simple one-way layout described above, the contrast does not need to be specified as the last coefficient will be tested in \code{glmQLFTest}.
Analyses with multiple groups should always provide an argument to \code{coef} or \code{contrasts} to avoid confusion.

<<label=bcvdiff,eval=FALSE,echo=FALSE>>=
y.diff <- estimateDisp(y.diff, design.diff)
plotBCV(y.diff)
@

<<label=qldiff,eval=FALSE,echo=FALSE>>=
fit.diff <- glmQLFit(y.diff, design.diff, robust=TRUE)
plotQLDisp(fit.diff)
result.diff <- glmQLFTest(fit.diff)
@

<<eval=FALSE>>=
<<bcvdiff>>
<<qldiff>>
@

\setkeys{Gin}{width=0.49\textwidth}
\begin{center}
<<fig=TRUE,echo=FALSE>>=
<<bcvdiff>>
@
<<fig=TRUE,echo=FALSE>>=
<<qldiff>>
@
\end{center}
\setkeys{Gin}{width=0.8\textwidth}

For completeness, if hetero-linker counts are sufficiently high, it may be possible to set up a paired-sample design.
In such a design, each library forms a homo-/hetero-linker pair, much like that described in Section~\ref{sec:paireddesign}.
All replicates in each group would have the same homo-/hetero-linker fold change.
The null hypothesis would then state that the fold change is equal between groups.

<<>>=
libname <- factor(c(1, 1, 2, 2, 3, 3, 4, 4))
combo <- factor(c("Ahom", "het", "Ahom", "het", "Bhom", "het", "Bhom", "het"))
design.diff2 <- model.matrix(~libname + combo)
design.diff2
@

The corresponding contrast would define the null as \code{groupBhom = 0} to equalize the homo-/hetero-linker fold change between groups.
This should avoid detection of any spurious changes in the homo-linker counts that are driven by non-specific ligation.
For example, an increase in all \code{Bhom} over \code{Ahom} will not be detected if there is an increase in the corresponding hetero-linker counts.
Of course, this is mostly academic given that hetero-linker counts are usually too low for practical use.

\section{Examination of the results}
A summary of the results can be obtained with a little work.
The non-zero codes indicate the number of interactions that are significantly different at a FDR threshold of 5\%.
The negative code indicates that the interaction is stronger in the K562 cells, whereas a positive code indicates that it is strong in the MCF7 cells.
Of course, one must be cautious when interpreting results from immortalized lines.
Any changes in interaction intensities may be driven by genomic rearrangements.

<<>>=
summary(decideTestsDGE(result.diff))
@

It is a trivial matter to save these results for further perusal.
The process of annotation and visualization will be skipped here for brevity, as it is the same as previously described.

<<>>=
ax <- anchors(comp.freq)
tx <- targets(comp.freq)
final <- data.frame(anchor.chr=seqnames(ax), anchor.start=start(ax), anchor.end=end(ax),
    target.chr=seqnames(tx), target.start=start(tx), target.end=end(tx), 
    result.diff$table, FDR=p.adjust(result.diff$table$PValue, method="BH"))
o <- order(final$PValue)
write.table(final[o,], file="dinter.tsv", sep="\t", quote=FALSE, row.names=FALSE)
@

\chapter{Epilogue}

\section{Session Information}
<<>>=
sessionInfo()
@

\section{References}
\bibliography{refchia}
\bibliographystyle{plainnat}
\end{document}
